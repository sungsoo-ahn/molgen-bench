# Default configuration for molecular generative model training

# Output directory for results (required by template conventions)
output_dir: data/default_experiment

# Data
data:
  dataset: qm9  # qm9 or mp20
  data_dir: ./data/downloaded
  batch_size: 128
  num_workers: 4
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1

# Model
architecture:
  type: gnn  # gnn, transformer, pairformer
  hidden_dim: 256
  num_layers: 6
  dropout: 0.1
  activation: relu

generative:
  type: flow_matching  # flow_matching, diffusion, stochastic_interpolant
  time_steps: 1000
  sigma_min: 0.001
  sigma_max: 1.0
  noise_schedule: cosine  # linear, cosine, polynomial

# Training
training:
  epochs: 500
  learning_rate: 1e-4
  weight_decay: 1e-5
  warmup_steps: 1000
  gradient_clip: 1.0
  ema_decay: 0.999

  # Scaling law experiments
  track_scaling: true
  log_interval: 100
  eval_interval: 1000
  checkpoint_interval: 5000

# Optimization
optimizer:
  type: adamw
  betas: [0.9, 0.999]
  eps: 1e-8

scheduler:
  type: cosine
  min_lr: 1e-6

# Evaluation
evaluation:
  num_samples: 10000
  batch_size: 256
  metrics:
    - validity
    - uniqueness
    - novelty
    - wasserstein
    - fcd
    - property_stats

# Logging
logging:
  output_dir: ./outputs
  experiment_name: default
  log_wandb: false
  wandb_project: molgen-bench

# Hardware
device: cuda
mixed_precision: true
compile: false  # torch.compile for PyTorch 2.0+
